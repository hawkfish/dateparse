(motivate why an NLP approach was considered. Also add technical detail on programming environment and parser used for grammar)

\subsection{Context-Free Grammar}
ICU date-time formats are well defined both structurally and semantically, and can be defined by a context-free grammar (CFG). A CFG consists of a set of non-terminal symbols $X$, a set of terminal symbols $\beta$, a start non-terminal symbol $S \in X$ from which the grammar generates the strings, and a set of production rules $\tau$, with each rule of the form $X \rightarrow \beta$~\cite{Hopcroft:1990}. 

While there are several functionally equivalent notations for representing CFG, we use the \textit{Backus-Naur Form} (BNF) for defining the grammar rules for \dateparse formats. In particular, we use the \textit{Extended Backus-Naur Form} (EBNF) as the notation is more compact and readable for frequently used constructions~\cite{Grune:1990}. 

We define a grammar for identifying date-time strings based on other EBNF based date-time formats [cite] as a reference. A partial definition of the grammar is found below (see supplementary material for complete definition):

\begin{grammar}
<TimeGrammar> ::= <Hours> ':' <Minutes> ':' <Seconds> ;\\

<DateGrammar> ::= <BigEndianDate> 
				\alt <MiddleEndianDate> 
				\alt <LittleEndianDate>;

<DateTimeGrammar>  ::= <DateGrammar> 
					\alt <TimeGrammar>;
					

<BigEndianDate> ::= <Year> <Month>  <Day> ;

<MiddleEndianDate> ::= <Month> <Day> <Year>;

<LittleEndianDate> ::= <Day> <Month> <Year>;

<Year> ::= <TwoYear> | <FourYear>;

<Month>  ::= <MonthFullForm> | <MonthAbbrForm> | <MonthLetterForm> | <MonthNumber>;

<Day>     ::= dd (between 01 and 28-31, depending on month/year);

<Hour> ::= <TwelveHour> | <TwentyFourHour>

<TwelveHour> ::= dd (between 00-12);

<TwentyFourHour> ::= dd (between 00 and 23);

<d> ::= `0' | `1' | `2' | `3' | `4' | `5' | `6' | `7' | `8' | `9'

\end{grammar}



\subsection{Translation to ICU Format}

\subsection{Production Rule Constraints and Variants}

The EBNF date-time grammar includes a large number of syntactically correct but semantically invalid
date-time expressions. While we have added range restrictions to symbols such as \texttt{Hour} (1--12 for 12-hour format and 1--24 for 24-hour format), \texttt{Days} (1--7), \texttt{Month} (1--12), there are special cases that need to be accounted for. For example, there is no  `November 31, 2015', `February 29, 2013', or `Sunday, May  5, 1965'. November only as 30 days in any year; 2013 was not a leap year; and May 5, 1965 was a Wednesday.

While custom production rules can be added to the existing grammar to exclude such expressions, this approach is not optimal as it leads to a rather large grammar that needs to account for every single semantically valid date-time sequence of terminal symbols. Rather, we modify the existing grammar with the following additional constraints to the \texttt{Day} terminal symbol for excluding such expressions:

\begin{itemize}
\item Restriction on the distribution of $30$ and $31$:
Months usually alternate between lengths of 30 and 31 days. We can use x mod 2 to get an alternating pattern of 1 and 0, then just add our constant base number of days:

\begin{equation}
\texttt{Day} = 30 + x \Mod 2
\end{equation}

where $x \in [1..12]$ for each of the $12$ months.

Except February, Equation $1$ addresses January and March through July. After July, the pattern should skip one, and the rest of the months should follow the alternating pattern inversely.

To obtain an inverse pattern of alternating 0 and 1, we add 1 to the dividend:

\begin{equation}
\texttt{Day} = 30 + (x + 1) \Mod 2
\end{equation}

In Equation $2$ the number of days for August through December is correct ($x \in [8..12]$), but not for the remaining months. We hence introduce a bit-masking function so that the equation is equal to 1 over the desired domain and 0 otherwise. Multiplying a term by this expression will result in the term being cancelled out outside its domain. To mask the latter piece of our function, we need an expression equal to $1$ where $8 \le x\le 12$. Floor division by 8 works well, since $x < 16$.

Now if we substitute this expression in the x + 1 dividend of Equation $2$, we can invert the pattern using our mask:

\begin{equation}
\texttt{Day} = 30 + (x + \floor{\frac{x}{8}}) \Mod 2
\end{equation}


\item LeapYear Restriction for February:
While the above restriction applies to all months barring February, we also apply a constraint to the number of days for February, based on whether the year is leap year or not. For this, we define a new symbol in the grammar called \texttt{LeapYear}. If an expression containing the month `February' or any such variant (\textit{e.g.} `Feb', `2') with the day `29' and a year, would need to resolve the \texttt{Year} symbol to be a \texttt{LeapYear}, defined as:

\begin{equation}
\texttt{Year} \Mod 4 == 0
\end{equation}

\end{itemize}

Equations $3$ and $4$ are now added as constraints to the \texttt{Days} symbol in the grammar.

\subsection{Probabilistic Context-Free Grammar}

Pattern-recognition problems such as parsing date and time formats initiate from observations generated by some structured stochastic process. In other words, even if the initial higher-level production rule of the grammar is known (i.e. date, time or date-time), there could be several directions that the parser resolves to. For example, in a date string \texttt{5/6/2015}, the pattern could either be \texttt{M/d/yyyy} or \texttt{d/M/yyyy}. 

In the context of CFGs, probabilities have been used to define a probability distribution over a set of parse trees defined by the CFG, and are a useful method for modeling such ambiguity~\cite{Collins:2003,Manning:1999}. The resulting formalism called Probabilistic Context-Free Grammar (PCFG), extends the CFG by assigning probabilities to the production rules of the grammar. During the process of parsing the date-time pattern, the probabilities are used as a filtering mechanism to rank the pattern(s) that a given string resolves to in the grammar. 

The production rules are of the form $ X \rightarrow \beta$ where $X$ is the left-hand side of the rule, while $\beta$ is the right-hand side.

Given a CFG grammar $G$, we define  $\tau_G(s)$ as the set of all possible parse trees for input date-time string $s$.  For any $X \rightarrow \beta \in \tau(G)$, the probability $p(X \rightarrow \beta) \ge 1$. In addition, $\sum_{(X \rightarrow \beta) \in \tau_{G}} = 1$. The parser then chooses the parse tree with the maximum probability, \textit{i.e.} given a date-time string $s$, as input, we determine the highest scoring parse tree $X \rightarrow \beta$ as  $max_{(X \rightarrow \beta) \in \tau(s)} p(X \rightarrow \beta)$.

In order to bootstrap the probability weights in the \texttt{PCFG}, we manually set initial probability weights to various rules in the grammar as follows:
\begin{itemize}
\item Similar to the MDL ranking properties described in Section 3.7, rules involving the non-terminal \texttt{DateGrammar} on the left-side of the rule, are assigned probability weights higher than those rules with the non-terminal being \texttt{TimeGrammar}. In practice, assigning $p(\texttt{DateGrammar} \rightarrow \beta_{1}) = 0.9$ and $p(\texttt{TimeGrammar} \rightarrow \beta_{2}) = 0.7$ leads to optimal ranking of the parse trees.

\item For the non-terminal symbol \texttt{Day}, the constraint specified is a range between 01 and 28-31, depending on month/year. However, for \texttt{dd} $> 12$, $p(\texttt{Day} \rightarrow d d) = 1.0$, and $0.5$ otherwise. This assignment helps disambiguate days from months.


\end{itemize}


(show cfg with prob values)
(examples -> one ambiguous, one not)
(parse tree with final probability weights)


\subsection{Supervised Learning}

Having defined initial probabilistic weights to the \texttt{PCFG}, we employ supervised learning with a known training set of date time formats to estimate the rule probabilities.  The training corpus is a set of files obtained from an online data analysis corpus, described in Section 5.

The occurrence frequencies of the rules in the correct
(disambiguated) parse trees can be determined from the corpus using the maximum-likelihood parameter estimates.
\begin{equation}
p(X \rightarrow \beta) = \frac{Count(X \rightarrow \beta)}{Count(X)}
\end{equation}

where $Count(X \rightarrow \beta)$ is the number of times that the rule $X \rightarrow \beta$ is seen in
the parse trees $\tau$, and $Count(X)$ is the number of times the non-terminal $X$ is seen in $\tau$. These frequencies can then be normalized into rule probabilities. This method produces accurate probability estimates when trained on a sufficiently large corpus of disambiguated parse trees. 


\subsection{Extensions}

\subsubsection{Columnar Context}
Once we have created a PCFG model of a process, we can apply existing PCFG parsing algorithms to identify a variety of date-time formats. However, the parser's success is often limited in the types of the dominant patterns that it can identify. In addition, the standard parsing techniques generally require specification of a complete observation sequence. In many contexts, we may have only a partial sequence available (\textit{e.g.} an incomplete entry). Finally, we may be interested in computing the probabilities of date-time patterns that the grammar may not explicitly define. To extend the forms of evidence, inferences, and pattern distributions supported, we need a flexible and expressive representation for the distribution of structures generated by the grammar. We adopt Bayesian networks for this purpose, and define an algorithm to generate a probabilistic distribution of possible parse trees corresponding to a set of date-time patterns as opposed to individual ones. 


\subsubsection{Locale and File Name Context}

%¥	Explain why we use a probabilistic version of the grammar
%¥	Explain how the production rules are created based on the ICU format
%¥	Extensions to the parser to account for columnar context for maximizing the probabilistic occurrence of the dominant pattern
%¥	Other semantic extensions Ð looking at the file name, adding rules for leap year, using external dictionaries for non-English terms
