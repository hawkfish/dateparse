Before delving into detailed descriptions of the two algorithms, we describe the common elements of the problem they are intended to solve. These are the input data, the output language and the interpretation of the output language for partial dates.

\subsection{Input Data}The training data and test data are taken from Public data sets. We selected a large number of string columns whose names suggested that they might contain temporal data. We included words from multiple languages besides English and extracted the column’s locale (actually the collation) along with the data.
\subsubsection{NULL Filtering}Each column was then reduced to a maximum sample set of 32. We excluded domain values that appeared to be representations of NULL:
\begin{itemize}\item Values containing the substring NULL\item Values containing no digits and at most one non-whitespace character (e.g. " / / ")\item Values on a list of empirically determined common NULL values (e.g. 0000-00-00, NaN)
\end{itemize}
Columns that had no remaining valid samples were discarded. 

\subsubsection{Sampling}The remaining samples were hashed and sorted on the hash value, with the top 32 values being retained as the column’s sample. We can increase the sample size if needed, but for dates, it appears to be an adequate number. In any case, the median number of non-null rows per domain in our test data is 50, so increasing the sample size would have little benefit.
\subsubsection{Numeric Timestamps}After NULL filtering, there remained one common class of date representation that was unsuited for parsing via our date format syntax, namely numeric timestamps. This included Unix epoch timestamps (expressed as second, millisecond or microsecond counts from 1970-01-01) and Microsoft Excel timestamps (expressed fractional days since 1900-01-01). A simple test to check that the column was numeric and inside a specific range of values representing recent dates allowed us to tag these columns to avoid analyzing them further (and incidentally to identify them for generating a simple date extraction calculation for the user.)
\subsection{The ICU Date Format Language}The date format syntax we selected is the one provided by the open-source project. We chose it because we were already using ICU in the code base, we had access to the source code and it provides localized date part data for a large number of languages.

The syntax is documented at the ICU web site [8]. While fairly complete, it has a few limitations that we ran into when evaluating the algorithms:
\begin{itemize}\item No support for 4 letter year abbreviations (e.g. Sept.)\item No support for ordinal days (e.g. July 4th)\item No support for quarter postfix notation (e.g. 2Q)\item No support for variant meridian markers (e.g. a.m.)
\end{itemize}
These limitations did not affect the results significantly, and in the future we hope to submit ICU extensions to handle some of these issues.

One other quirk of the ICU syntax may be a contributing factor to the user confusion around writing correct ICU date formats. The use of lexicographical case in the meta-symbols of the format language can be confusing (e.g. y is used for years, but M is used for months while m is used for minutes.) Another advantage of an automated algorithm is that it hides such problems from most users, significantly improving the usability of the function.

\subsection{Partial Dates}Many of the date formats that we encountered were incomplete dates, which necessitated creating rules for what date scalar they represented.
ICU’s date parsing APIs allow the specification of default values for parts when a format does not contain them. In our implementation, all time fields are set to 0 (midnight) and the date fields are set based on whether the format contains any date part specifications. When date parts are present, we use 2000-01-01 as the set of default date parts as it is the start of a leap year. When dealing with pure time formats, we use 1899-12-30, (which is the date used internally by Tableau to signal pure time values.)

ICU will also parse Time Zones (which we recognize but do not use in Tableau) and Quarters (which we interpret as the first month of the period.) RDBMSes such as Oracle and Postgres that support time zones will be able to take advantage of the generated time zone field.